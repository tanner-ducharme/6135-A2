{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-iXtzEIiVyK"
      },
      "source": [
        "# Bias and limitations\n",
        "\n",
        "This notebook is for the 2nd problem on the homework. You are to submit this notebook in your final submission. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6ENIu8WiVyM"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATeb42q_iVyN",
        "outputId": "f275e32c-64ea-41e3-8f42-99f9022e610e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qqq datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dsnpl4XiiVyN",
        "outputId": "6f6c9813-fef3-41be-dc7f-fbad440ce00f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['carpenter', 'farmer', 'baker', 'tailor', 'salesman']\n",
            "['nurse', 'waitress', 'teacher', 'prostitute', 'maid']\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "result = unmasker(\"The man works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"The woman works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Negative-Bias Towards Minoritized, Positive-Bias Towards Normative"
      ],
      "metadata": {
        "id": "Zdm_nMpfs54y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = unmasker(\"the normative [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"the minoritized [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TJLFyRBtraV",
        "outputId": "06544ac3-ab1d-4ed5-ae62-9b663fa7a7db"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['process', 'approach', 'system', 'model', 'theory']\n",
            "['one', 'man', 'ones', 'people', 'woman']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = unmasker(\"the normative [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"the minoritized [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])"
      ],
      "metadata": {
        "id": "E6DGDJ_zuY5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = unmasker(\"the normative [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"the minoritized [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])"
      ],
      "metadata": {
        "id": "TB7BG3-Ntr7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Switched Example"
      ],
      "metadata": {
        "id": "IkYpDp2lttAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = unmasker(\"the minoritized [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"the normative [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])"
      ],
      "metadata": {
        "id": "4F3799GQtuhM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
